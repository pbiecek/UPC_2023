<!DOCTYPE html>
<html lang="en"><head>
<script src="BarcelonaTech_day4_files/libs/clipboard/clipboard.min.js"></script>
<script src="BarcelonaTech_day4_files/libs/quarto-html/tabby.min.js"></script>
<script src="BarcelonaTech_day4_files/libs/quarto-html/popper.min.js"></script>
<script src="BarcelonaTech_day4_files/libs/quarto-html/tippy.umd.min.js"></script>
<link href="BarcelonaTech_day4_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="BarcelonaTech_day4_files/libs/quarto-html/quarto-html.min.css" rel="stylesheet" data-mode="light">
<link href="BarcelonaTech_day4_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.2.313">

  <meta name="author" content="Przemyslaw Biecek">
  <title>quarto-inputf5588c53</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="BarcelonaTech_day4_files/libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="BarcelonaTech_day4_files/libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="BarcelonaTech_day4_files/libs/revealjs/dist/theme/quarto.css" id="theme">
  <link href="BarcelonaTech_day4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="BarcelonaTech_day4_files/libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="BarcelonaTech_day4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="BarcelonaTech_day4_files/libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="BarcelonaTech_day4_files/libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="BarcelonaTech_day4_files/libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">

  .callout {
    margin-top: 1em;
    margin-bottom: 1em;  
    border-radius: .25rem;
  }

  .callout.callout-style-simple { 
    padding: 0em 0.5em;
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
    display: flex;
  }

  .callout.callout-style-default {
    border-left: solid #acacac .3rem;
    border-right: solid 1px silver;
    border-top: solid 1px silver;
    border-bottom: solid 1px silver;
  }

  .callout .callout-body-container {
    flex-grow: 1;
  }

  .callout.callout-style-simple .callout-body {
    font-size: 1rem;
    font-weight: 400;
  }

  .callout.callout-style-default .callout-body {
    font-size: 0.9rem;
    font-weight: 400;
  }

  .callout.callout-captioned.callout-style-simple .callout-body {
    margin-top: 0.2em;
  }

  .callout:not(.callout-captioned) .callout-body {
      display: flex;
  }

  .callout:not(.no-icon).callout-captioned.callout-style-simple .callout-content {
    padding-left: 1.6em;
  }

  .callout.callout-captioned .callout-header {
    padding-top: 0.2em;
    margin-bottom: -0.2em;
  }

  .callout.callout-captioned .callout-caption  p {
    margin-top: 0.5em;
    margin-bottom: 0.5em;
  }
    
  .callout.callout-captioned.callout-style-simple .callout-content  p {
    margin-top: 0;
  }

  .callout.callout-captioned.callout-style-default .callout-content  p {
    margin-top: 0.7em;
  }

  .callout.callout-style-simple div.callout-caption {
    border-bottom: none;
    font-size: .9rem;
    font-weight: 600;
    opacity: 75%;
  }

  .callout.callout-style-default  div.callout-caption {
    border-bottom: none;
    font-weight: 600;
    opacity: 85%;
    font-size: 0.9rem;
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-default div.callout-content {
    padding-left: 0.5em;
    padding-right: 0.5em;
  }

  .callout.callout-style-simple .callout-icon::before {
    height: 1rem;
    width: 1rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 1rem 1rem;
  }

  .callout.callout-style-default .callout-icon::before {
    height: 0.9rem;
    width: 0.9rem;
    display: inline-block;
    content: "";
    background-repeat: no-repeat;
    background-size: 0.9rem 0.9rem;
  }

  .callout-caption {
    display: flex
  }
    
  .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  .callout.no-icon::before {
    display: none !important;
  }

  .callout.callout-captioned .callout-body > .callout-content > :last-child {
    margin-bottom: 0.5rem;
  }

  .callout.callout-captioned .callout-icon::before {
    margin-top: .5rem;
    padding-right: .5rem;
  }

  .callout:not(.callout-captioned) .callout-icon::before {
    margin-top: 1rem;
    padding-right: .5rem;
  }

  /* Callout Types */

  div.callout-note {
    border-left-color: #4582ec !important;
  }

  div.callout-note .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEU0lEQVRYCcVXTWhcVRQ+586kSUMMxkyaElstCto2SIhitS5Ek8xUKV2poatCcVHtUlFQk8mbaaziwpWgglJwVaquitBOfhQXFlqlzSJpFSpIYyXNjBNiTCck7x2/8/LeNDOZxDuEkgOXe++553zfefee+/OYLOXFk3+1LLrRdiO81yNqZ6K9cG0P3MeFaMIQjXssE8Z1JzLO9ls20MBZX7oG8w9GxB0goaPrW5aNMp1yOZIa7Wv6o2ykpLtmAPs/vrG14Z+6d4jpbSKuhdcSyq9wGMPXjonwmESXrriLzFGOdDBLB8Y6MNYBu0dRokSygMA/mrun8MGFN3behm6VVAwg4WR3i6FvYK1T7MHo9BK7ydH+1uurECoouk5MPRyVSBrBHMYwVobG2aOXM07sWrn5qgB60rc6mcwIDJtQrnrEr44kmy+UO9r0u9O5/YbkS9juQckLed3DyW2XV/qWBBB3ptvI8EUY3I9p/67OW+g967TNr3Sotn3IuVlfMLVnsBwH4fsnebJvyGm5GeIUA3jljERmrv49SizPYuq+z7c2H/jlGC+Ghhupn/hcapqmcudB9jwJ/3jvnvu6vu5lVzF1fXyZuZZ7U8nRmVzytvT+H3kilYvH09mLWrQdwFSsFEsxFVs5fK7A0g8gMZjbif4ACpKbjv7gNGaD8bUrlk8x+KRflttr22JEMRUbTUwwDQScyzPgedQHZT0xnx7ujw2jfVfExwYHwOsDTjLdJ2ebmeQIlJ7neo41s/DrsL3kl+W2lWvAga0tR3zueGr6GL78M3ifH0rGXrBC2aAR8uYcIA5gwV8zIE8onoh8u0Fca/ciF7j1uOzEnqcIm59sEXoGc0+z6+H45V1CvAvHcD7THztu669cnp+L0okAeIc6zjbM/24LgGM1gZk7jnRu1aQWoU9sfUOuhrmtaPIO3YY1KLLWZaEO5TKUbMY5zx8W9UJ6elpLwKXbsaZ4EFl7B4bMtDv0iRipKoDQT2sNQI9b1utXFdYisi+wzZ/ri/1m7QfDgEuvgUUEIJPq3DhX/5DWNqIXDOweC2wvIR90Oq3lDpdMIgD2r0dXvGdsEW5H6x6HLRJYU7C69VefO1x8Gde1ZFSJLfWS1jbCnhtOPxmpfv2LXOA2Xk2tvnwKKPFuZ/oRmwBwqRQDcKNeVQkYcOjtWVBuM/JuYw5b6isojIkYxyYAFn5K7ZBF10fea52y8QltAg6jnMqNHFBmGkQ1j+U43HMi2xMar1Nv0zGsf1s8nUsmUtPOOrbFIR8bHFDMB5zL13Gmr/kGlCkUzedTzzmzsaJXhYawnA3UmARpiYj5ooJZiUoxFRtK3X6pgNPv+IZVPcnwbOl6f+aBaO1CNvPW9n9LmCp01nuSaTRF2YxHqZ8DYQT6WsXT+RD6eUztwYLZ8rM+rcPxamv1VQzFUkzFXvkiVrySGQgJNvXHJAxiU3/NwiC03rSf05VBaPtu/Z7/B8Yn/w7eguloAAAAAElFTkSuQmCC');
  }

  div.callout-note.callout-style-default .callout-caption {
    background-color: #dae6fb
  }

  div.callout-important {
    border-left-color: #d9534f !important;
  }

  div.callout-important .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAEKklEQVRYCcVXTWhcVRS+575MJym48A+hSRFr00ySRQhURRfd2HYjk2SSTokuBCkU2o0LoSKKraKIBTcuFCoidGFD08nkBzdREbpQ1EDNIv8qSGMFUboImMSZd4/f9zJv8ibJMC8xJQfO3HPPPef7zrvvvnvviIkpC9nsw0UttFunbUhpFzFtarSd6WJkStVMw5xyVqYTvkwfzuf/5FgtkVoB0729j1rjXwThS7Vio+Mo6DNnvLfahoZ+i/o32lULuJ3NNiz7q6+pyAUkJaFF6JwaM2lUJlV0MlnQn5aTRbEu0SEqHUa0A4AdiGuB1kFXRfVyg5d87+Dg4DL6m2TLAub60ilj7A1Ec4odSAc8X95sHh7+ZRPCFo6Fnp7HfU/fBng/hi10CjCnWnJjsxvDNxWw0NfV6Rv5GgP3I3jGWXumdTD/3cbEOP2ZbOZp69yniG3FQ9z1jD7bnBu9Fc2tKGC2q+uAJOQHBDRiZX1x36o7fWBs7J9ownbtO+n0/qWkvW7UPIfc37WgT6ZGR++EOJyeQDSb9UB+DZ1G6DdLDzyS+b/kBCYGsYgJbSQHuThGKRcw5xdeQf8YdNHsc6ePXrlSYMBuSIAFTGAtQo+VuALo4BX83N190NWZWbynBjhOHsmNfFWLeL6v+ynsA58zDvvAC8j5PkbOcXCMg2PZFk3q8MjI7WAG/Dp9AwP7jdGBOOQkAvlFUB+irtm16I1Zw9YBcpGTGXYmk3kQIC/Cds55l+iMI3jqhjAuaoe+am2Jw5GT3Nbz3CkE12NavmzN5+erJW7046n/CH1RO/RVa8lBLozXk9uqykkGAyRXLWlLv5jyp4RFsG5vGVzpDLnIjTWgnRy2Rr+tDKvRc7Y8AyZq10jj8DqXdnIRNtFZb+t/ZRtXcDiVnzpqx8mPcDWxgARUqx0W1QB9MeUZiNrV4qP+Ehc+BpNgATsTX8ozYKL2NtFYAHc84fG7ndxUPr+AR/iQSns7uSUufAymwDOb2+NjK27lEFocm/EE2WpyIy/Hi66MWuMKJn8RvxIcj87IM5Vh9663ziW36kR0HNenXuxmfaD8JC7tfKbrhFr7LiZCrMjrzTeGx+PmkosrkNzW94ObzwocJ7A1HokLolY+AvkTiD/q1H0cN48c5EL8Crkttsa/AXQVDmutfyku0E7jShx49XqV3MFK8IryDhYVbj7Sj2P2eBxwcXoe8T8idsKKPRcnZw1b+slFTubwUwhktrfnAt7J++jwQtLZcm3sr9LQrjRzz6cfMv9aLvgmnAGvpoaGLxM4mAEaLV7iAzQ3oU0IvD5x9ix3yF2RAAuYAOO2f7PEFWCXZ4C9Pb2UsgDeVnFSpbFK7/IWu7TPTvBqzbGdCHOJQSxiEjt6IyZmxQyEJHv6xyQsYk//moVFsN2zP6fRImjfq7/n/wFDguUQFNEwugAAAABJRU5ErkJggg==');
  }

  div.callout-important.callout-style-default .callout-caption {
    background-color: #f7dddc
  }

  div.callout-warning {
    border-left-color: #f0ad4e !important;
  }

  div.callout-warning .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAAETklEQVRYCeVWW2gcVRg+58yaTUnizqbipZeX4uWhBEniBaoUX1Ioze52t7sRq6APio9V9MEaoWlVsFasRq0gltaAPuxms8lu0gcviE/FFOstVbSIxgcv6SU7EZqmdc7v9+9mJtNks51NTUH84ed889/PP+cmxP+d5FIbMJmNbpREu4WUkiTtCicKny0l1pIKmBzovF2S+hIJHX8iEu3hZJ5lNZGqyRrGSIQpq15AzF28jgpeY6yk6GVdrfFqdrD6Iw+QlB8g0YS2g7dyQmXM/IDhBhT0UCiRf59lfqmmDvzRt6kByV/m4JjtzuaujMUM2c5Z2d6JdKrRb3K2q6mA+oYVz8JnDdKPmmNthzkAk/lN63sYPgevrguc72aZX/L9C6x09GYyxBgCX4NlvyGUHOKELlm5rXeR1kchuChJt4SSwyddZRXgvwMGvYo4QSlk3/zkHD8UHxwVJA6zjZZqP8v8kK8OWLnIZtLyCAJagYC4rTGW/9Pqj92N/c+LUaAj27movwbi19tk/whRCIE7Q9vyI6yvRpftAKVTdUjOW40X3h5OXsKCdmFcx0xlLJoSuQngnrJe7Kcjm4OMq9FlC7CMmScQANuNvjfP3PjGXDBaUQmbp296S5L4DrpbrHN1T87ZVEZVCzg1FF0Ft+dKrlLukI+/c9ENo+TvlTDbYFvuKPtQ9+l052rXrgKoWkDAFnvh0wTOmYn8R5f4k/jN/fZiCM1tQx9jQQ4ANhqG4hiL0qIFTGViG9DKB7GYzgubnpofgYRwO+DFjh0Zin2m4b/97EDkXkc+f6xYAPX0KK2I/7fUQuwzuwo/L3AkcjugPNixC8cHf0FyPjWlItmLxWw4Ou9YsQCr5fijMGoD/zpdRy95HRysyXA74MWOnscpO4j2y3HAVisw85hX5+AFBRSHt4ShfLFkIMXTqyKFc46xdzQM6XbAi702a7sy04J0+feReMFKp5q9esYLCqAZYw/k14E/xcLLsFElaornTuJB0svMuJINy8xkIYuL+xPAlWRceH6+HX7THJ0djLUom46zREu7tTkxwmf/FdOZ/sh6Q8qvEAiHpm4PJ4a/doJe0gH1t+aHRgCzOvBvJedEK5OFE5jpm4AGP2a8Dxe3gGJ/pAutug9Gp6he92CsSsWBaEcxGx0FHytmIpuqGkOpldqNYQK8cSoXvd+xLxXADw0kf6UkJNFtdo5MOgaLjiQOQHcn+A6h5NuL2s0qsC2LOM75PcF3yr5STuBSAcGG+meA14K/CI21HcS4LBT6tv0QAh8Dr5l93AhZzG5ZJ4VxAqdZUEl9z7WJ4aN+svMvwHHL21UKTd1mqvChH7/Za5xzXBBKrUcB0TQ+Ulgkfbi/H/YT5EptrGzsEK7tR1B7ln9BBwckYfMiuSqklSznIuoIIOM42MQO+QnduCoFCI0bpkzjCjddHPN/F+2Yu+sd9bKNpVwHhbS3LluK/0zgfwD0xYI5dXuzlQAAAABJRU5ErkJggg==');
  }

  div.callout-warning.callout-style-default .callout-caption {
    background-color: #fcefdc
  }

  div.callout-tip {
    border-left-color: #02b875 !important;
  }

  div.callout-tip .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAADr0lEQVRYCe1XTWgTQRj9ZjZV8a9SPIkKgj8I1bMHsUWrqYLVg4Ue6v9BwZOxSYsIerFao7UiUryIqJcqgtpimhbBXoSCVxUFe9CTiogUrUp2Pt+3aUI2u5vdNh4dmMzOzHvvezuz8xNFM0mjnbXaNu1MvFWRXkXEyE6aYOYJpdW4IXuA4r0fo8qqSMDBU0v1HJUgVieAXxzCsdE/YJTdFcVIZQNMyhruOMJKXYFoLfIfIvVIMWdsrd+Rpd86ZmyzzjJmLStqRn0v8lzkb4rVIXvnpScOJuAn2ACC65FkPzEdEy4TPWRLJ2h7z4cArXzzaOdKlbOvKKX25Wl00jSnrwVxAg3o4dRxhO13RBSdNvH0xSARv3adTXbBdTf64IWO2vH0LT+cv4GR1DJt+DUItaQogeBX/chhbTBxEiZ6gftlDNXTrvT7co4ub5A6gp9HIcHvzTa46OS5fBeP87Qm0fQkr4FsYgVQ7Qg+ZayaDg9jhg1GkWj8RG6lkeSacrrHgDaxdoBiZPg+NXV/KifMuB6//JmYH4CntVEHy/keA6x4h4CU5oFy8GzrBS18cLJMXcljAKB6INjWsRcuZBWVaS3GDrqB7rdapVIeA+isQ57Eev9eCqzqOa81CY05VLd6SamW2wA2H3SiTbnbSxmzfp7WtKZkqy4mdyAlGx7ennghYf8voqp9cLSgKdqNfa6RdRsAAkPwRuJZNbpByn+RrJi1RXTwdi8RQF6ymDwGMAtZ6TVE+4uoKh+MYkcLsT0Hk8eAienbiGdjJHZTpmNjlbFJNKDVAp2fJlYju6IreQxQ08UJDNYdoLSl6AadO+fFuCQqVMB1NJwPm69T04Wv5WhfcWyfXQB+wXRs1pt+nCknRa0LVzSA/2B+a9+zQJadb7IyyV24YAxKp2Jqs3emZTuNnKxsah+uabKbMk7CbTgJx/zIgQYErIeTKRQ9yD9wxVof5YolPHqaWo7TD6tJlh7jQnK5z2n3+fGdggIOx2kaa2YI9QWarc5Ce1ipNWMKeSG4DysFF52KBmTNMmn5HqCFkwy34rDg05gDwgH3bBi+sgFhN/e8QvRn8kbamCOhgrZ9GJhFDgfcMHzFb6BAtjKpFhzTjwv1KCVuxHvCbsSiEz4CANnj84cwHdFXAbAOJ4LTSAawGWFn5tDhLMYz6nWeU2wJfIhmIJBefcd/A5FWQWGgrWzyORZ3Q6HuV+Jf0Bj+BTX69fm1zWgK7By1YTXchFDORywnfQ7GpzOo6S+qECrsx2ifVQAAAABJRU5ErkJggg==');
  }

  div.callout-tip.callout-style-default .callout-caption {
    background-color: #ccf1e3
  }

  div.callout-caution {
    border-left-color: #fd7e14 !important;
  }

  div.callout-caution .callout-icon::before {
    background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAAAIKADAAQAAAABAAAAIAAAAACshmLzAAACV0lEQVRYCdVWzWoUQRCuqp2ICBLJXgITZL1EfQDBW/bkzUMUD7klD+ATSHBEfAIfQO+iXsWDxJsHL96EHAwhgzlkg8nBg25XWb0zIb0zs9muYYWkoKeru+vn664fBqElyZNuyh167NXJ8Ut8McjbmEraKHkd7uAnAFku+VWdb3reSmRV8PKSLfZ0Gjn3a6Xlcq9YGb6tADjn+lUfTXtVmaZ1KwBIvFI11rRXlWlatwIAAv2asaa9mlB9wwygiDX26qaw1yYPzFXg2N1GgG0FMF8Oj+VIx7E/03lHx8UhvYyNZLN7BwSPgekXXLribw7w5/c8EF+DBK5idvDVYtEEwMeYefjjLAdEyQ3M9nfOkgnPTEkYU+sxMq0BxNR6jExrAI31H1rzvLEfRIdgcv1XEdj6QTQAS2wtstEALLG1yEZ3QhH6oDX7ExBSFEkFINXH98NTrme5IOaaA7kIfiu2L8A3qhH9zRbukdCqdsA98TdElyeMe5BI8Rs2xHRIsoTSSVFfCFCWGPn9XHb4cdobRIWABNf0add9jakDjQJpJ1bTXOJXnnRXHRf+dNL1ZV1MBRCXhMbaHqGI1JkKIL7+i8uffuP6wVQAzO7+qVEbF6NbS0LJureYcWXUUhH66nLR5rYmva+2tjRFtojkM2aD76HEGAD3tPtKM309FJg5j/K682ywcWJ3PASCcycH/22u+Bh7Aa0ehM2Fu4z0SAE81HF9RkB21c5bEn4Dzw+/qNOyXr3DCTQDMBOdhi4nAgiFDGCinIa2owCEChUwD8qzd03PG+qdW/4fDzjUMcE1ZpIAAAAASUVORK5CYII=');
  }

  div.callout-caution.callout-style-default .callout-caption {
    background-color: #ffe5d0
  }

  </style>
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title"><p><img data-src="figures/barcelona.png" style="width:9in"></p></h1>
  <p class="subtitle">Day 4: Variable Importance and Fairness</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Przemyslaw Biecek 
</div>
</div>
</div>

</section>
<section>
<section id="paper-of-the-day-12" class="title-slide slide level1 center">
<h1>Paper of the day (1/2)</h1>
<div class="cell">
<style type="text/css">
.reveal {
  font-size: 24px;
  line-height: 1.6!important;
}
code {
  font-size: 18px!important;
  line-height: 1.2!important;
}
pre {
  line-height: 1.2!important;
}
</style>
</div>
<p><br><br><br></p>

<img data-src="mid/mid_paper_01.png" class="r-stretch"></section>
<section id="all-models-are-wrong-but-many-are-useful" class="slide level2">
<h2>All Models are Wrong, but Many are Useful</h2>
<ul>
<li>Today we will talk about Permutational Variable Importance.</li>
<li>The idea is quite old. It was used by Breiman, among others, in the construction of random forests.</li>
<li>But today we will talk about its more general formulation introduced in <a href="https://arxiv.org/abs/1801.01489">All Models are Wrong, but Many are Useful: Learning a Variable’s Importance by Studying an Entire Class of Prediction Models Simultaneously</a> by Aaron Fisher, Cynthia Rudin and Francesca Dominici.</li>
</ul>
<p>
</p><center>
<img src="images/vip_abstract.png" width="80%">
</center>
<p></p>
</section>
<section id="all-models-are-wrong-but-many-are-useful-in-numbers" class="slide level2">
<h2>,,All Models are Wrong, but Many are Useful’’ in numbers</h2>
<ul>
<li>The ,,All Models are Wrong, but Many are Useful’’ paper is published on arXiv since 2018</li>
<li>Now (2022) it has 919 citations which shows an amazing adoption of presented ideas</li>
<li>The paper refers to interesting but kind of forgotten idea of Rashomon perspectives and leads to the discussion about traceability of important variables if their contributions are not independent.</li>
</ul>
<p>
</p><center>
<img src="images/vip_popular.png" width="85%">
</center>
<p></p>
</section>
<section id="xai-pyramid" class="slide level2">
<h2>XAI pyramid</h2>
<ul>
<li>Thinking about the XAI pyramid -&gt; we return to the second level of the pyramid, level related to variable importance</li>
<li>We focus on explanations for a single variable but all presented methods may be extended to two or more variables</li>
</ul>
<p>
</p><center>
<img src="images/xai_piramide_vip.png" width="70%">
</center>
<p></p>
</section>
<section id="rashomon-perspective" class="slide level2">
<h2>Rashomon perspective</h2>
<p>There are many references to Rashomon’s perspective in the paper. What is it about?</p>
<p>
</p><center>
<img src="images/rashomon.png" width="90%">
</center>
<p></p>
</section>
<section id="statistical-modeling-the-two-cultures.-12" class="slide level2">
<h2>Statistical Modeling: The Two Cultures. 1/2</h2>
<p>Leo Beriman’s paper from 20 years ago is an absolute classic today. The article touches on many topics that are more and more relevant from decade to decade.</p>
<p>The main storyline is the difference in approach to data analysis between the two tribes: statistical and algorithmic.</p>
<p>
</p><center>
<img src="images/cultures1.png" width="75%">
</center>
<p></p>
<p>From <a href="http://www2.math.uu.se/~thulin/mm/breiman.pdf">Statistical Modeling: The Two Cultures</a></p>
</section>
<section id="statistical-modeling-the-two-cultures.-22" class="slide level2">
<h2>Statistical Modeling: The Two Cultures. 2/2</h2>
<p>One of the interesting issues in this paper is the Rashomon perspective. Many models can have very similar performance but very different descriptions of the data.</p>
<p>If we are interested in the importance of variables, why do we get so fixated on analysing just one of these models?</p>
<p>
</p><center>
<img src="images/cultures2.png" width="75%">
</center>
<p></p>
<p>From <a href="http://www2.math.uu.se/~thulin/mm/breiman.pdf">Statistical Modeling: The Two Cultures</a></p>
</section></section>
<section>
<section id="variable-importance" class="title-slide slide level1 center">
<h1>Variable importance</h1>
<p><br><br><br></p>

<img data-src="mid/mid_rashomon_01.png" class="r-stretch"></section>
<section id="variable-importance-for-random-forest" class="slide level2">
<h2>Variable importance for Random Forest</h2>
<p>From: <a href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#varimp">https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#varimp</a></p>
<p><em>In every tree grown in the forest, put down the OOB cases and count the number of votes cast for the correct class. Now randomly permute the values of variable m in the OOB cases and put these cases down the tree. Subtract the number of votes for the correct class in the variable-m-permuted OOB data from the number of votes for the correct class in the untouched OOB data. The average of this number over all trees in the forest is the raw importance score for variable m.</em></p>
<p><em>If the values of this score from tree to tree are independent, then the standard error can be computed by a standard computation. The correlations of these scores between trees have been computed for a number of data sets and proved to be quite low, therefore we compute standard errors in the classical way, divide the raw score by its standard error to get a z-score, ands assign a significance level to the z-score assuming normality.</em></p>
<p><em>For each case, consider all the trees for which it is OOB. Subtract the percentage of votes for the correct class in the variable-m-permuted oob data from the percentage of votes for the correct class in the untouched oob data. This is the local importance score for variable m for this case.</em></p>
<p>
</p><center>
<img src="images/rashomon_rf.png" width="90%">
</center>
<p></p>
</section>
<section id="do-we-need-a-new-measure-for-variable-importance" class="slide level2">
<h2>Do we need a new measure for Variable Importance?</h2>
<p>Let’s return to ,,All Models are Wrong…’’</p>
<p>From: <a href="http://www.jmlr.org/papers/volume20/18-760/18-760.pdf">http://www.jmlr.org/papers/volume20/18-760/18-760.pdf</a></p>
<p><em>Several common approaches for variable selection, or for describing relationships between variables, do not necessarily capture a variable’s importance. Null hypothesis testing methods may identify a relationship, but do <strong>not describe the relationship’s strength</strong>. Similarly, checking whether a variable is included by a sparse model-fitting algorithm, such as the Lasso (Hastie et al., 2009), <strong>does not describe the extent to which the variable is relied on.</strong> Partial dependence plots (Breiman et al., 2001; Hastie et al., 2009) <strong>can be difficult to interpret if multiple variables are of interest, or if the prediction model contains interaction effects</strong> .</em></p>
<p><em>Another common VI procedure is to run a model-fitting algorithm twice, first on all of the data, and then again after removing X1 from the data set. The losses for the <strong>two resulting models are then compared to determine the importance, or “necessity,” of X1</strong> (Gevrey et al., 2003). Because this measure is a function of two prediction models rather than one, it does not measure how much either individual model relies on X1.</em></p>
</section>
<section id="motivation" class="slide level2">
<h2>Motivation</h2>
<p>We need</p>
<ul>
<li>Model agnostic procedure for assessment of variable importance</li>
<li>Assessment of stability/uncertainty beyond the measure of variable importance</li>
<li>Rashomon perspective -&gt; use many (good) models to understand significance of a selected variable</li>
</ul>
</section>
<section id="model-reliance" class="slide level2">
<h2>Model Reliance</h2>
<p>Variable importance as the drop in the loss after permutation of variable <span class="math inline">\(i\)</span>.</p>
<p><span class="math display">\[
MR(f) = \frac{E\ Loss\ f\ under\ noise}{E\ Loss\ f\ without\ noise}.
\]</span></p>
<p>Noise should make <span class="math inline">\(X_i\)</span> uninformative to <span class="math inline">\(Y\)</span> keeping the marginal distribution of <span class="math inline">\(X_i\)</span>.</p>
<p>Example estimator</p>
<p><span class="math display">\[
\widehat{MR}(f) = \frac{\hat e_{switch}(f)}{\hat e_{orig}(f)},
\]</span></p>
<p>where</p>
<p><span class="math display">\[
\hat e_{orig}(f) = \frac 1n \sum_{i=1}^n L(f(y_i; X_{1,i};X_{2,i}))
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\hat e_{switch}(f) = \frac 1{n(n-1)} \sum_{i=1}^n \sum_{j\neq i} L(f(y_j; X_{1,i};X_{2,j})).
\]</span></p>
</section>
<section id="model-reliance-yet-another-estimator" class="slide level2">
<h2>Model Reliance – yet another estimator</h2>
<p>One can estimate this ratio in a more computationally efficient way</p>
<p><span class="math display">\[
\hat e_{divide}(f) = \frac 1{2[n/2]} \sum_{i=1}^{[n/2]} L(f(y_i; X_{1,i+[n/2]};X_{2,i})) + L(f(y_{i+[n/2]}; X_{1,i};X_{2,{i+[n/2]}})).
\]</span></p>
<p>But the easiest way is to permute the value of the variable <span class="math inline">\(x_i\)</span>. This preserves the distribution by destroying the dependence on Y.</p>
<p><span class="math display">\[
\hat e_{permute}(f) = \frac 1{n} \sum_{i=1}^{n} L(f(y_i; X_{1,\pi(i)};X_{2,i})),
\]</span> where <span class="math inline">\(\pi\)</span> is a random permutation over <span class="math inline">\(\{1, ..., n\}\)</span>.</p>
</section>
<section id="example-fifa" class="slide level2">
<h2>Example: FIFA</h2>
<p>Example importance of variables for few selected models: random forest, logistic regression, gradient boosing. Note that importance scores are different between models. Because we have regression task in FIFA data, then here we are using RMSE as a loss function.</p>
<p>From <a href="https://ema.drwhy.ai/">Explanatory Model Analysis</a>.</p>
<p>
</p><center>
<img src="images/vip_fifa.png" width="90%">
</center>
<p></p>
</section>
<section id="model-class-reliance" class="slide level2">
<h2>Model Class Reliance</h2>
<p>One model is not enough. Let’s consider <span class="math inline">\(\varepsilon\)</span>-Rashomon set – set of models with performance <span class="math inline">\(\varepsilon\)</span>-close to a reference model <span class="math inline">\(f_{ref}\)</span>. More formally:</p>
<p><span class="math display">\[
\mathcal R(\varepsilon, f_{ref}, \mathcal F) = \{f \in \mathcal F: e_{orig}(f) \leq e_{orig}(f_{ref}) + \varepsilon \}.
\]</span></p>
<p>We can now define the importance of a variable not for a single model but for the entire class, we will call it <em>Model Class Reliance</em></p>
<p><span class="math display">\[
[MCR_-(\varepsilon), MCR_+(\varepsilon)] = \left[ \min_{f\in \mathcal R(\varepsilon)} MR(f); \max_{f\in \mathcal R(\varepsilon)} MR(f) \right].
\]</span></p>
<p>
</p><center>
<img src="images/rashomon2.png" width="70%">
</center>
<p></p>
<p>From <a href="https://arxiv.org/abs/1801.01489">All Models are Wrong, but Many are Useful</a>.</p>
</section>
<section id="rashomons-perspective-open-questions" class="slide level2">
<h2>Rashomon’s perspective: open questions</h2>
<p>In the paper <a href="https://arxiv.org/abs/2103.11251">Interpretable machine learning: Fundamental principles and 10 grand challenges</a> the main challenges facing XAI techniques are presented. One of them is: <strong>9. Characterization of the ,,Rashomon’’ set of good models</strong>.</p>
<p>This is an area of active research, currently mainly focused in linear models and tree models.</p>
<p>
</p><center>
<img src="images/rashomon3.png" width="70%">
</center>
<p></p>
</section></section>
<section>
<section id="other-approaches-to-variable-importance" class="title-slide slide level1 center">
<h1>Other approaches to Variable importance</h1>
<p><br><br><br></p>

<img data-src="mid/mid_rashomon_01.png" class="r-stretch"></section>
<section id="average-absolute-shap" class="slide level2">
<h2>Average absolute SHAP</h2>
<p>Of course, there are many other ways to determine the importance of variables in a model agnostic way.</p>
<p>We have previously discussed the usefulness of scores based on SHAP values.</p>
<p><span class="math display">\[
vip^{SHAP}_j = \frac 1n \sum_i |\phi^{SHAP}_{i,j}|.
\]</span></p>
<p>
</p><center>
<img src="images/SHAP_vip.png" width="60%">
</center>
<p></p>
</section>
<section id="oscillations-of-partial-dependence" class="slide level2">
<h2>Oscillations of Partial Dependence</h2>
<p>Similarly, one can construct measures of importance of variables based on partial dependence profiles. These are model agnostic too.</p>
<p>
</p><center>
<img src="images/profile_v4_rf2.png" width="90%">
</center>
<p></p>
</section>
<section id="friedmans-h-statistic" class="slide level2">
<h2>Friedman’s H-Statistic</h2>
<p>In a similar way, we can construct importance measures not only for one variable, but for interactions, e.g.&nbsp;of two variables.</p>
<p>We will say that pairwise interactions occur if</p>
<p><span class="math display">\[
E_X \left[ \frac{\partial^2 F(x)}{\partial x_j \partial x_k} \right]^2 &gt; 0.
\]</span></p>
<p>Let’s recall simplified definition of Partial Dependence Profiles for set of variables <span class="math inline">\(S\)</span> (in the estimation, the expected value is replaced by the mean).</p>
<p><span class="math display">\[
F_S(x_S) = E_{X_{-S}} \left[ F(x_S, x_{-S}) \right].
\]</span></p>
<p>After the paper <a href="https://arxiv.org/pdf/0811.1679.pdf">Predictive learning via rule ensembles</a> (Jerome Friedman, Bogdan Popescu) we can define H-Statistic for pair of variables <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span>.</p>
<p><span class="math display">\[
H^2_{jk} = \frac{\sum_i  [\hat F_{jk} (x_{ij}, x_{ik}) - \hat F_{j} (x_{ij}) - \hat F_{k} (x_{ik}) ]^2}{\sum_i \hat F^2_{jk} (x_{ij}, x_{ik}) }.
\]</span></p>
<p>In similar way we can do this for one or more variables.</p>
</section></section>
<section>
<section id="paper-book-of-the-day-22" class="title-slide slide level1 center">
<h1><del>Paper</del> Book of the day (2/2)</h1>
<p><br><br><br></p>

<img data-src="mid/mid_paper_01.png" class="r-stretch"></section>
<section id="fairness-and-machine-learning" class="slide level2">
<h2>Fairness and Machine Learning</h2>
<ul>
<li>Today we will talk about fairness measures and fairness concepts translated into the ML world. Most of these results were introduced in <a href="https://fairmlbook.org/">Fairness and Machine Learning. Limitations and Opportunities</a> by Solon Barocas, Moritz Hardt, and Arvind Narayanan (scholars from Berkeley, Cornell, and Princeton)</li>
</ul>
<p>
</p><center>
<img src="images/fairness_abstract.png" width="80%">
</center>
<p></p>
</section>
<section id="fairness-and-machine-learning-in-numbers" class="slide level2">
<h2>Fairness and Machine Learning in numbers</h2>
<ul>
<li>The Fairness&amp;ML book was published online in 2018</li>
<li>The paper version is still not published but the online version has already over 1000 citations</li>
<li>The book introduces not only fairness measures but also a very interesting framework for critical thinking about fairness and biases in the solution development process that involves ML methods.</li>
</ul>
<p>
<img src="images/fairness_popular.png" width="100%">
</p>
</section></section>
<section>
<section id="motivation-1" class="title-slide slide level1 center">
<h1>Motivation</h1>
<p><br><br><br></p>

<img data-src="mid/mid_fairness_01.png" class="r-stretch"></section>
<section id="is-discrimination-an-issue-here" class="slide level2">
<h2>Is discrimination an issue here?</h2>
<p>From our first lecture:</p>
<ul>
<li>For example, a system showing job ads for truck drivers, presenting these ads more often to men aged 20-50. Is this an example of age and gender discrimination or an increase in the chance of getting an employee?</li>
<li>Who should define who should watch the selected advertisement and when</li>
</ul>
<p>Read more: <a href="https://www.propublica.org/article/facebook-ads-can-still-discriminate-against-women-and-older-workers-despite-a-civil-rights-settlement">https://www.propublica.org</a></p>
<p>
</p><center>
<img src="images/fairness_02.png" width="80%">
</center>
<p></p>
</section>
<section id="is-discrimination-an-issue-here-1" class="slide level2">
<h2>Is discrimination an issue here?</h2>
<p>A high-profile case with a bias leading to gender discrimination in Amazon’s CV screening system.</p>
<p>The bias learned from historical data reflected not the quality of employees but the decisions taken by recruiters!</p>
<p>Bias was visible in, for example, the names of secondary schools which in the UK system sometimes allow gender to be identified.</p>
<p>
<img src="images/xai_fairness_01.png" width="100%">
</p>
</section>
<section id="is-discrimination-an-issue-here-2" class="slide level2">
<h2>Is discrimination an issue here?</h2>
<p>Interestingly, more women work at Amazon than at other IT giants.</p>
<p>No discrimination if you don’t try to measure it?</p>
<p>
<img src="images/xai_fairness_06.png" width="100%">
</p>
</section>
<section id="is-discrimination-an-issue-here-3" class="slide level2">
<h2>Is discrimination an issue here?</h2>
<p>A little story, perhaps funny, but a true story. A simple hand detection system in a soap dispenser was poorly calibrated and failed to detect hands in people with darker skin colour.</p>
<p>
<img src="images/xai_fairness_02.png" width="100%">
</p>
</section>
<section id="is-discrimination-an-issue-here-4" class="slide level2">
<h2>Is discrimination an issue here?</h2>
<p>Still fun or already something serious?</p>
<p>Photos of Hollywood actors and actresses have different percentages of people of different skin colours than the population of the whole country (here the USA) and certainly different than the whole world.</p>
<p>If we build a system of judging beauty standards on such images, won’t it be naturally biased?</p>
<p>
<img src="images/xai_fairness_03.png" width="100%">
</p>
</section>
<section id="is-discrimination-an-issue-here-5" class="slide level2">
<h2>Is discrimination an issue here?</h2>
<p>And systems for image synthesis or style transfer?</p>
<p>Can one be offended if a GAN intended to enhance attractiveness bleaches a person’s skin? It may sound ridiculous, but what if there are thousands of operations or dramas of oversensitive people behind such assessments?</p>
<p>
<img src="images/xai_fairness_04.png" width="100%">
</p>
</section>
<section id="is-discrimination-an-issue-here-6" class="slide level2">
<h2>Is discrimination an issue here?</h2>
<p>One of the best-known yet most controversial cases – is the COMPAS model supporting recidivism risk prediction.</p>
<p>In 2016, the Pro Publica Foundation presented an example of an analysis showing discrimination against black convicts by this model. Since then, there have been many arguments against this model as well as defending the model. We will devote more attention to it in the second part of the lecture.</p>
<p>
<img src="images/xai_fairness_07.png" width="100%">
</p>
</section></section>
<section>
<section id="source-of-bias" class="title-slide slide level1 center">
<h1>Source of bias</h1>
<p><br><br><br></p>

<img data-src="mid/mid_fairness_01.png" class="r-stretch"></section>
<section id="what-does-it-mean-to-discriminate" class="slide level2">
<h2>What does it mean to discriminate?</h2>
<p>Concerning European law</p>
<p>
<img src="images/handbook_01.png" width="100%">
</p>
</section>
<section id="what-does-it-mean-to-discriminate-1" class="slide level2">
<h2>What does it mean to discriminate?</h2>
<p>Concerning European law</p>
<p>
<img src="images/handbook_02.png" width="100%">
</p>
</section>
<section id="what-does-it-mean-to-discriminate-2" class="slide level2">
<h2>What does it mean to discriminate?</h2>
<p>The situation in the USA is different. The highlighted factors are defined as protected attributes within the USA but not in Europe.</p>
<p>Different history - different problems and legislation.</p>
<p>
<img src="images/handbook_03.png" width="100%">
</p>
</section>
<section id="some-sources-of-bias" class="slide level2">
<h2>Some sources of bias</h2>
<p>Partially based on <a href="https://www.nature.com/articles/s41746-020-0288-5">Cirillo et al, 2020</a>.</p>
<ul>
<li><strong>Historical bias.</strong> The data are correctly sampled and correspond well to the observed relationships, but due to different treatments in the past, some prejudices are encoded in the data. Think about gender and occupation stereotypes</li>
</ul>
<div class="fragment">
<ul>
<li><strong>Representation bias.</strong> The available data is not a representative sample of the population of interest. Think about the available facial images of actors, often white men. Or genetic sequences of covid variants mostly collected in developed European countries. Or crime statistics in the regions to which the police are directed.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Measurement bias.</strong> The variable of interest is not directly observable or is difficult to measure and the way it is measured may be distorted by other factors. Think of the results of the mathematics skills assessment (e.g.&nbsp;PISA) measured by tasks on computers not that widely available in some countries.</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Evaluation bias.</strong> The evaluation of the algorithm is performed on a population that does not represent all groups. Think of a lung screening algorithm tested primarily on a population of smokers (older men).</li>
</ul>
</div>
<div class="fragment">
<ul>
<li><strong>Proxy bias.</strong> The algorithm uses variables that are proxies for protected attributes. Think of male/female-only schools where the gender effect can be hidden under the school effect.</li>
</ul>
</div>
</section>
<section id="desirable-and-undesirable-bias" class="slide level2">
<h2>Desirable and undesirable bias</h2>
<p>Not every difference in treatment is harmful. Sometimes it is possible to treat the genders differently to both benefit from these differences (e.g.&nbsp;when choosing appropriately gender-specific drugs).</p>
<p>A very interesting discussion on the so-called desirable bias can be found in the article <a href="https://www.nature.com/articles/s41746-020-0288-5">Sex and gender differences and biases in artificial intelligence for biomedicine and healthcare (2020), Cirillo et al</a>.</p>
<p>
<img src="images/healthcare_01.png" width="100%">
</p>
</section>
<section id="where-is-bias" class="slide level2">
<h2>Where is bias?</h2>
<p>Let us assume that we already know what bias is. At what point in the development of the model can it appear?</p>
<p>It turns out that at any point.</p>
<p>
<img src="images/fairness_process_02.png" width="100%">
</p>
</section>
<section id="where-is-bias-1" class="slide level2">
<h2>Where is bias?</h2>
<p>A very interesting example of an unexpected bias is the StreetBumps project from Boston.</p>
<p>Initially, it seemed that an app on smartphones is a panacea for many of the problems of identifying spots that need repair in the city.</p>
<p>But…</p>
<p>
<img src="images/fairness_process_03.png" width="100%">
</p>
</section></section>
<section>
<section id="fairness-metrics" class="title-slide slide level1 center">
<h1>Fairness metrics</h1>
<p><br><br><br></p>

<img data-src="mid/mid_fairness_01.png" class="r-stretch"></section>
<section id="notation" class="slide level2">
<h2>Notation</h2>
<p>
<img src="images/fairness_measure_01.png" width="100%">
</p>
<ul>
<li>Let <span class="math inline">\(A \in \{a,b, ...\}\)</span> stand for protected group and values <span class="math inline">\(A \neq a\)</span> denote membership to unprivileged subgroups while <span class="math inline">\(A = a\)</span> membership to privileged subgroup. To simplify the notation, we will treat this as a binary variable (so <span class="math inline">\(A = b\)</span> will denote membership to an unprivileged subgroup), but all results hold if <span class="math inline">\(A\)</span> has a larger number of groups.<br>
</li>
<li>Let <span class="math inline">\(Y \in \{0,1\}\)</span> be a binary label (binary target = binary classification) where <span class="math inline">\(1\)</span> is preferred, favorable outcome.</li>
<li>Let <span class="math inline">\(S \in [0,1]\)</span> be a probabilistic score of the model, and <span class="math inline">\(\hat{Y} \in \{0,1\}\)</span> is the binarised model response, so <span class="math inline">\(\hat{Y} = 1\)</span> when <span class="math inline">\(S \geq 0.5\)</span>, otherwise <span class="math inline">\(\hat{Y} = 0\)</span>.</li>
</ul>
<p>Here are possible situations for the subgroup <span class="math inline">\(A=a\)</span>. We can draw up the same table for each of the subgroups.</p>
</section>
<section id="group-fairness-statistical-parity-independence-demographic-parity" class="slide level2">
<h2>Group fairness / statistical parity / independence / demographic parity</h2>
<p>
<img src="images/fairness_measure_02.png" width="100%">
</p>
</section>
<section id="group-fairness-statistical-parity-independence-demographic-parity-1" class="slide level2">
<h2>Group fairness / statistical parity / independence / demographic parity</h2>
<p>
<img src="images/fairness_measure_04.png" width="100%">
</p>
<p>It would be hard for any classifier to maintain the same relations between subgroups. That is why some margins around the perfect agreement are needed. To address this issue, we accepted the four-fifths rule as the benchmark for discrimination rate, which states that <em>“A selection rate for any race, sex, or ethnic group which is less than four-fifths (<em><span class="math inline">\(\frac{4}{5}\)</span></em>) (or eighty percent) of the rate for the group with the highest rate will generally be regarded by the Federal enforcement agencies as evidence of adverse impact[…].”</em> The selection rate is originally represented by statistical parity, but we adopted this rule to define acceptable rates between subgroups for all metrics. There are a few caveats to the preceding citation concerning the size of the sample and the boundary itself. Nevertheless, the four-fifths rule is an excellent guideline to adhere to. In the implementation, this boundary is represented by <span class="math inline">\(\varepsilon\)</span>, and it is adjustable by the user, but the default value will be 0.8. This rule is often used, but users should check if the fairness criteria should be set differently in each case.</p>
</section>
<section id="equal-opportunity" class="slide level2">
<h2>Equal opportunity</h2>
<p>
<img src="images/fairness_measure_05.png" width="100%">
</p>
</section>
<section id="predictive-equality" class="slide level2">
<h2>Predictive equality</h2>
<p>
<img src="images/fairness_measure_06.png" width="100%">
</p>
</section>
<section id="equalized-odds-separation-positive-rate-parity" class="slide level2">
<h2>Equalized odds, Separation, Positive Rate Parity</h2>
<p>
<img src="images/fairness_measure_07.png" width="100%">
</p>
</section>
<section id="positive-predictive-parity" class="slide level2">
<h2>Positive Predictive Parity</h2>
<p>
<img src="images/fairness_measure_08.png" width="100%">
</p>
</section>
<section id="negative-predictive-parity" class="slide level2">
<h2>Negative Predictive Parity</h2>
<p>
<img src="images/fairness_measure_09.png" width="100%">
</p>
</section>
<section id="predictive-rate-parity-sufficiency" class="slide level2">
<h2>Predictive Rate Parity, Sufficiency</h2>
<p>
<img src="images/fairness_measure_10.png" width="100%">
</p>
</section>
<section id="whether-to-sentence-a-prisoner" class="slide level2">
<h2>Whether to sentence a prisoner</h2>
<p>
<img src="images/fairness_measure_11.png" width="100%">
</p>
<p>Let us illustrate the intuition behind Independence, Separation, and Sufficiency criteria using the well-known example of the COMPAS model for estimating recidivism risk. Fulfilling the Independence criterion means that the rate of sentenced prisoners should be equal in each subpopulation. It can be said that such an approach is fair from society’s perspective.</p>
<p>Fulfilling the Separation criterion means that the fraction of innocents/guilty sentenced should be equal in subgroups. Such an approach is fair from the prisoner’s perspective. The reasoning is the following: <em>“If I am innocent, I should have the same chance of acquittal regardless of sub-population”</em>. This was the expectation presented by the ProPublica Foundation in their study.</p>
<p>Meeting the Sufficiency criterion means that there should be an equal fraction of innocents among the convicted, similarly, for the non-convicted. This approach is fair from the judge’s perspective. The reasoning is the following: <em>“If I convicted someone, he should have the same chance of being innocent regardless of the sub-population”</em>. This approach is presented by the company developing the COMPAS model, Northpointe. Unfortunately, as we have already written, it is not possible to meet all these criteria at the same time.</p>
<p>While defining the metrics above, we assumed only two subgroups. This was done to facilitate notation, but there might be more unprivileged subgroups. A perfectly fair model would pass all criteria for each subgroup.</p>
<p>However tempting it is to think that all the criteria described above can be met at the same time, unfortunately, this is not possible. Barocas et al.&nbsp;(2019) show that, apart from a few hypothetical situations, no two of <em>{Independence, Separation, Sufficiency}</em> can be fulfilled simultaneously. So we are left balancing between the degree of imbalance of the different criteria or deciding to control only one criterion.</p>
</section>
<section id="the-fairness-trade-off-the-impossibility-theorem" class="slide level2">
<h2>The Fairness Trade-off (the impossibility theorem)</h2>
<ul>
<li>Except for trivial cases all these criteria cannot be satisfied jointly.</li>
<li>In fact, each two out of {Sufficiency, Separation, Independence} are mutually exclusive.</li>
</ul>
<p>Source: <a href="https://fairmlbook.org/">https://fairmlbook.org/</a></p>
</section>
<section id="you-cant-be-fair-but-you-can-know-how-unfair-you-are" class="slide level2">
<h2>You can’t be fair, but you can know how unfair you are</h2>
<p>The possible fulfilment of fairness can be summarised in a single graph - the fairness check.</p>
<p>
</p><center>
<img src="images/fairness_measure_13.png" width="70%">
</center>
<p></p>
<p>The four-fifths rule (Code of Federal Regulations, 1978):</p>
<p><em>“A selection rate for any race, sex, or ethnic group which is less than four-fifths (4 / 5) (or eighty percent) of the rate for the group with the highest rate will generally be regarded by the Federal enforcement agencies as evidence of adverse impact[…].”</em></p>
</section></section>
<section>
<section id="mitigation" class="title-slide slide level1 center">
<h1>Mitigation</h1>
<p><br><br><br></p>

<img data-src="mid/mid_fairness_01.png" class="r-stretch"></section>
<section id="bias-mitigation-strategies" class="slide level2">
<h2>Bias mitigation strategies</h2>
<ul>
<li><strong>Data Pre-processing.</strong> Change data to improve model performance, for example, use subsampling or case weighting.</li>
<li><strong>Model In-processing.</strong> Modify the optimized criterion to include fairness functions, e.g.&nbsp;through adversarial training</li>
<li><strong>Model Post-processing.</strong> Modify the resulting model scores or final decisions, e.g., using different thresholds.</li>
</ul>
</section>
<section id="demo" class="slide level2">
<h2>Demo</h2>
<p>AI Fairness 360 - Demo: <a href="https://aif360.mybluemix.net/data">https://aif360.mybluemix.net/data</a></p>
<p>
<img src="images/fairness_demo.png" width="100%">
</p>
</section></section>
<section>
<section id="take-home-message" class="title-slide slide level1 center">
<h1>Take-home message</h1>
<p><br><br><br></p>

<img data-src="mid/mid_home_01.png" class="r-stretch"></section>
<section class="slide level2">

<ul>
<li><p><strong>Why would we use only one model</strong> to infer the importance of a variable? This is very old-fashioned thinking. We should use the Rashomon perspective instead.</p></li>
<li><p>The idea of <strong>permutation importance</strong> of variables was <strong>presented in the article on random forests</strong> by Leo Breiman. But it is transferable to other model classes.</p></li>
<li><p>An interesting alternative is Model Class Reliance. It allows you to capture the <strong>importance</strong> of a variable not only from the perspective of a single model but of an <strong>entire class of models</strong>.</p></li>
<li><p>There are many other approaches to assessing the importance of a variable or pairs of variables (interactions). How to assess which are better? This is an interesting problem for research.</p></li>
<li><p>Rashomon is an old film, but why not watch it sometime soon?</p></li>
<li><p>Not every difference in the treatment of groups is discrimination. There are <strong>desirable</strong> and <strong>undesirable</strong> sources of <strong>bias</strong>.</p></li>
<li><p>A number of different measures are used to evaluate the fairness of a model. And while it is <strong>impossible to satisfy them all</strong>, it is useful to know what they measure in order to choose the <strong>right measure in the right situation</strong>.</p></li>
</ul>
</section></section>
<section>
<section id="hands-on" class="title-slide slide level1 center">
<h1>Hands-on</h1>
<p><br><br><br></p>

<img data-src="mid/mid_hands_01.png" class="r-stretch"></section>
<section id="step-6.-variable-importance" class="slide level2">
<h2>Step 6. Variable-importance</h2>
<h3 id="sars-cov-2-case-study">SARS-COV-2 case study</h3>
<p>See: <a href="https://rml.mi2.ai/06_vi.html">https://rml.mi2.ai/06_vi.html</a></p>

<img data-src="figures/comic_08.png" class="r-stretch"></section></section>
<section>
<section id="references" class="title-slide slide level1 center">
<h1>References</h1>
<p><br><br><br></p>

<img data-src="mid/mid_references_01.png" class="r-stretch"></section>
<section id="references-1" class="slide level2">
<h2>References</h2>
<ul>
<li>eXplainable Machine Learning course for Machine Learning (MSc) studies at the University of Warsaw. <a href="https://github.com/mim-uw/eXplainableMachineLearning-2023">https://github.com/mim-uw/eXplainableMachineLearning-2023</a></li>
<li>Explanatory Model Analysis. Explore, Explain, and Examine Predictive Models. With examples in R and Python. <a href="https://ema.drwhy.ai/">https://ema.drwhy.ai/</a></li>
<li>The Hitchhiker’s Guide to Responsible Machine Learning. Shorter summary of EMA book. <a href="https://rml.mi2.ai/">https://rml.mi2.ai/</a></li>
</ul>

<img src="figures/XAI.png" class="slide-logo r-stretch"><div class="footer footer-default">
<p>BarcelonaTech Summer School – 22/06/2023</p>
</div>
</section></section>
    </div>
  </div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/notes/notes.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/search/search.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="BarcelonaTech_day4_files/libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'smaller': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":false},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const clipboard = new window.ClipboardJS('.code-copy-button', {
        target: function(trigger) {
          return trigger.previousElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      });
      function tippyHover(el, contentFn) {
        const config = {
          allowHTML: true,
          content: contentFn,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto-reveal',
          placement: 'bottom-start'
        };
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          return note.innerHTML;
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>